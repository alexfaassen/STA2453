{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "## Script imports\n",
    "import simuFlares\n",
    "from STL_IF import STLIF\n",
    "import detectFlare\n",
    "from sigma_clip import sigma_clip\n",
    "## Simulation status\n",
    "from IPython.display import clear_output\n",
    "\n",
    "## Setup\n",
    "# Load Data\n",
    "pdcsap = pd.read_csv(\"../0.Data/031381302.csv\", index_col = 'time').loc[:, [\"pdcsap_flux\"]].dropna()\n",
    "# Calm interval\n",
    "pdcsap = pdcsap.query(\"1442 <= index <= 1449\")\n",
    "inds = np.arange(pdcsap.shape[0])\n",
    "\n",
    "## Flare parameters\n",
    "num_flares = 5\n",
    "# Base half-peak timescale: larger values => all flares last longer (relative to their amplitudes)\n",
    "t_half = 2.5  # e.g. 10 minutes (2-min cadence)\n",
    "# Flare ampltiude (Pareto) parameters\n",
    "xm = 10         # Scale (~ x_min): Baseline amplitude (values will rarely be smaller than this)\n",
    "alpha = 1       # Shape: smaller => heavier tail = more large flares.\n",
    "offset = 30     # Offset amplitudes (shift)\n",
    "upper = 100     # Amplitude cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 100 runs:\n",
      "STLIF:\n",
      "  Avg Precision: 1.000\n",
      "  Avg Recall:    0.900\n",
      "  Avg F1 Score:  0.941\n",
      "3-3sigma:\n",
      "  Avg Precision: 1.000\n",
      "  Avg Recall:    0.776\n",
      "  Avg F1 Score:  0.858\n"
     ]
    }
   ],
   "source": [
    "## Isolation Forest parameters\n",
    "contamination = 0.001 # Expected proportion of anomalies\n",
    "n_estimators = 100 # Number of trees\n",
    "sample_size = 256 # Number of samples used to train each tree\n",
    "\n",
    "## Simulate\n",
    "n = 100 # Number of simulations\n",
    "stlif_metrics = []\n",
    "sigma_metrics = []\n",
    "\n",
    "for i in range(n):\n",
    "    ## Simulation status\n",
    "    clear_output(wait=True)\n",
    "    print(i)\n",
    "\n",
    "    ## Simulate flares\n",
    "    flare_lightcurve, flare_times = simuFlares.kepler_flare(\n",
    "        inds,                           # time array\n",
    "        t_half,                         # base half-peak width\n",
    "        num_flares,                     # number of flares\n",
    "        flux_dist=simuFlares.rpareto,   # amplitude distribution\n",
    "        xm=xm, alpha=alpha, offset=offset, upper=upper\n",
    "    )\n",
    "    # Inject flares\n",
    "    data = pdcsap.copy()\n",
    "    data[\"pdcsap_flux\"] += flare_lightcurve\n",
    "\n",
    "    ## Run model: STLIF\n",
    "    data = STLIF(data, contamination=contamination, n_estimators=n_estimators, sample_size=sample_size)\n",
    "\n",
    "    # Calculate metrics\n",
    "    prec, rec, f1 = detectFlare.event_level_scores(real_flares=flare_times, y_pred=data[\"anomaly\"].values)\n",
    "    stlif_metrics.append((prec, rec, f1))\n",
    "\n",
    "    ## Run model: STLSigmaClip\n",
    "    # Note: Uses detrended series from STLIF output.\n",
    "    anomalies = sigma_clip(data['resid'], sigma=3.0, consecutive_pts=3).ravel()\n",
    "\n",
    "    # Calculate metrics\n",
    "    prec, rec, f1 = detectFlare.event_level_scores(real_flares=flare_times, y_pred=anomalies)\n",
    "    sigma_metrics.append((prec, rec, f1))\n",
    "\n",
    "## Compute average metrics\n",
    "avg_prec, avg_rec, avg_f1 = np.array(stlif_metrics).mean(axis=0)\n",
    "\n",
    "# Print results\n",
    "print(f\"After {n} runs:\")\n",
    "print(\"STLIF:\")\n",
    "print(f\"  Avg Precision: {avg_prec:.3f}\")\n",
    "print(f\"  Avg Recall:    {avg_rec:.3f}\")\n",
    "print(f\"  Avg F1 Score:  {avg_f1:.3f}\")\n",
    "\n",
    "## Compute average metrics\n",
    "avg_prec, avg_rec, avg_f1 = np.array(sigma_metrics).mean(axis=0)\n",
    "\n",
    "print(\"3-3sigma:\")\n",
    "print(f\"  Avg Precision: {avg_prec:.3f}\")\n",
    "print(f\"  Avg Recall:    {avg_rec:.3f}\")\n",
    "print(f\"  Avg F1 Score:  {avg_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Isolation Forest parameters\n",
    "# Expected proportion of anomalies\n",
    "contamination_values = [0.001, 0.005]#, 0.01, 0.02]\n",
    "# Number of trees\n",
    "n_estimators_values = [100]#, 200]\n",
    "# Number of samples used to train each tree\n",
    "max_samples_values = [256]#, \"auto\"]\n",
    "\n",
    "## Simulate\n",
    "n_runs = 10 # Number of simulations\n",
    "results = []\n",
    "k = 1 # Counter\n",
    "\n",
    "# Create a small param grid\n",
    "param_grid = []\n",
    "for c in contamination_values:\n",
    "    for ne in n_estimators_values:\n",
    "        for ms in max_samples_values:\n",
    "            param_grid.append((c, ne, ms))\n",
    "\n",
    "for (contamination, n_est, m_samp) in param_grid:\n",
    "    ## Simulation status\n",
    "    clear_output(wait=True)\n",
    "    print(\"Simulation: \", k, \" (contamination=\", contamination, \", n_est=\", n_est, \", m_samp=\", m_samp, \")\")\n",
    "\n",
    "    ## Setup\n",
    "    run_metrics = []\n",
    "    \n",
    "    for run_i in range(n_runs):\n",
    "        ## Simulate flares\n",
    "        flare_lightcurve, flare_times = simuFlares.kepler_flare(\n",
    "            inds,                           # time array\n",
    "            t_half,                         # base half-peak width\n",
    "            num_flares,                     # number of flares\n",
    "            flux_dist=simuFlares.rpareto,   # amplitude distribution\n",
    "            xm=xm, alpha=alpha, offset=offset, upper=upper\n",
    "        )\n",
    "        # Inject flares\n",
    "        data = pdcsap.copy()\n",
    "        data[\"pdcsap_flux\"] += flare_lightcurve\n",
    "\n",
    "        ## Run model: STLIF\n",
    "        data = STLIF(data, contamination=contamination, n_estimators=n_est, sample_size=m_samp)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        prec, rec, f1 = detectFlare.event_level_scores(real_flares=flare_times, y_pred=data[\"anomaly\"].values)\n",
    "        run_metrics.append((prec, rec, f1))\n",
    "    \n",
    "    # Average performance over n_runs\n",
    "    avg_prf = np.mean(run_metrics, axis=0)\n",
    "    result_dict = {\n",
    "        \"contamination\": contamination,\n",
    "        \"n_estimators\": n_est,\n",
    "        \"max_samples\": m_samp,\n",
    "        \"avg_precision\": avg_prf[0],\n",
    "        \"avg_recall\":    avg_prf[1],\n",
    "        \"avg_f1_score\":  avg_prf[2],\n",
    "    }\n",
    "    results.append(result_dict)\n",
    "\n",
    "# Sort results by F1\n",
    "results.sort(key=lambda x: x[\"avg_f1_score\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for &: 'str' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m k \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBAH: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'str' and 'tuple'"
     ]
    }
   ],
   "source": [
    "k = (\"a\", \"b\" , 3)\n",
    "\n",
    "print(\"BAH: \" & k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
